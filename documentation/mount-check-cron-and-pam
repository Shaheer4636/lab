
# S3 Mount Health Check Monitoring with Cron & CloudWatch

This guide documents how we configured S3 mount health monitoring using a cron job, logged the results, and streamed logs to CloudWatch. It also includes how we resolved PAM-related cron execution issues.

---

## Overview

- Monitor if `/mnt/buyspeed-arkansas-stage` (S3 mount) is active
- Log health status every minute to `/var/log/s3_mount_monitor.log`
- Send logs to AWS CloudWatch
- Solve PAM error blocking cron from running as `root`

---

## Step 1: Install and Configure CloudWatch Agent

### 1.1 Install the CloudWatch Agent

On Amazon Linux / RHEL:

```bash
sudo yum install amazon-cloudwatch-agent -y
```

On Ubuntu/Debian:

```bash
sudo apt install amazon-cloudwatch-agent -y
```

### 1.2 IAM Role Permissions for EC2

Attach this IAM policy:

`CloudWatchAgentServerPolicy`

Or a custom version with:

```json
{
  "Effect": "Allow",
  "Action": [
    "logs:CreateLogGroup",
    "logs:CreateLogStream",
    "logs:PutLogEvents"
  ],
  "Resource": "*"
}
```

### 1.3 Agent Configuration File

Create this file:

```bash
sudo nano /etc/amazon-cloudwatch-agent.json
```

Paste:

```json
{
  "logs": {
    "logs_collected": {
      "files": {
        "collect_list": [
          {
            "file_path": "/var/log/s3_mount_monitor.log",
            "log_group_name": "/s3/monitoring",
            "log_stream_name": "buyspeed-arkansas-stage-{instance_id}",
            "timestamp_format": "%Y-%m-%d %H:%M:%S"
          }
        ]
      }
    }
  }
}
```

### 1.4 Start the CloudWatch Agent

```bash
sudo /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl   -a append-config   -m ec2   -c file:/etc/amazon-cloudwatch-agent.json   -s
```

---

## Step 2: Create S3 Mount Monitoring Script

### 2.1 Create Script File

```bash
sudo nano /usr/local/bin/check_s3_mount.sh
```

Paste the following:

```bash
#!/bin/bash

MOUNT_PATH="/mnt/buyspeed-arkansas-stage"
LOG_FILE="/var/log/s3_mount_monitor.log"
DEBUG_LOG="/tmp/cron_debug.log"
TIMESTAMP=$(/bin/date '+%Y-%m-%d %H:%M:%S')

echo "$TIMESTAMP: Script started" >> "$DEBUG_LOG"
echo "Checking mount path: $MOUNT_PATH" >> "$DEBUG_LOG"
echo "Running command: /bin/mountpoint -q $MOUNT_PATH" >> "$DEBUG_LOG"

if /bin/mountpoint -q "$MOUNT_PATH"; then
    echo "$TIMESTAMP: OK - $MOUNT_PATH is active" >> "$LOG_FILE"
    echo "$TIMESTAMP: Mount is active" >> "$DEBUG_LOG"
    exit 0
else
    EXIT_CODE=$?
    echo "$TIMESTAMP: ERROR - $MOUNT_PATH is NOT active (exit code: $EXIT_CODE)" >> "$LOG_FILE"
    echo "$TIMESTAMP: Mount is NOT active (exit code: $EXIT_CODE)" >> "$DEBUG_LOG"
    exit 1
fi
```

### 2.2 Make the Script Executable

```bash
chmod +x /usr/local/bin/check_s3_mount.sh
```

---

## Step 3: Set Up Cron Job via `/etc/cron.d`

### 3.1 Create a Cron File

```bash
sudo nano /etc/cron.d/s3mount
```

Paste this:

```cron
SHELL=/bin/bash
PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin

* * * * * root /bin/bash /usr/local/bin/check_s3_mount.sh >> /tmp/cron_debug.log 2>&1
```

### 3.2 Set Correct Permissions

```bash
sudo chmod 644 /etc/cron.d/s3mount
```

### 3.3 Restart Cron Service

```bash
sudo systemctl restart crond
```

---

## Step 4: Fix PAM Blocking Cron

### 4.1 Problem Observed

Cron logs showed:

```
PAM ERROR (Permission denied)
FAILED to authorize user with PAM
```

### 4.2 Solution: Allow Root in PAM (if needed)

```bash
sudo nano /etc/security/access.conf
```

Add this line at the top:

```
+ : root : ALL
```

Only do this if using `/etc/cron.d` still results in PAM errors. Otherwise, it's not required.

---

## Step 5: Validate Itâ€™s Working

- View mount logs:

```bash
tail -f /var/log/s3_mount_monitor.log
```

- View cron debug logs:

```bash
tail -f /tmp/cron_debug.log
```

- Check CloudWatch:

Log Group: `/s3/monitoring`

---

## Notes for ASG/AMI Environments

- This setup should be included in:
  - Your custom AMI, or
  - A bootstrap script (cloud-init / user-data), or
  - Managed through config management tools (Ansible, SSM, etc.)
